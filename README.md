# CartPole-v0
This repository is about the solutions that i use to solve CartPole-v0 in GYM. Some of them are folowing the tutorial in the web. I will explain the solutions i used for this enviroment.

[//]: # (image reference )
[Q-networkreSult]: ./ ""
[newImgs]: ./newImgs.png "newImgs"
[DQN-cartPole-tenosflow-result]: ./DQN-cartPole-tenosflow-result.png "DQN-cartPole-tenosflow-result"
[DQN-cartPole-P_replay-result]: ./DQN-cartPole-P_replay-result.png "DQN-cartPole-P_replay-result"
[DDQN-cartPole-2000]: ./DDQN-cartPole-2000.png "DDQN-cartPole-2000"
[DQN-cartPole-result]: ./DQN-cartPole-result.png "DQN-cartPole-result"

----
### [Q-network (DQN)](###Q-network )###
### [DQN with experience replay Keras](#Q-netowrk with experience replay keras)
### [DQN with experience replay Tensoflow](#Q-netowrk with experience replay keras)
### [DDQN with prioritized experience replay](#DDQN with prioritized experience replay keras)
----

### Deep Q-network with experience replay Keras

![finalGraph][finalGraph]
---

### DQN with experience replay Keras

![DQN-cartPole-result][DQN-cartPole-result]
---

### DQN with experience replay Tensoflow

![DQN-cartPole-tenosflow-result][DQN-cartPole-tenosflow-result]
---

### DDQN with prioritized experience replay

![DDQN-cartPole-2000][DDQN-cartPole-2000]
